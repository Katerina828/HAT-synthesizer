{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLclassifier import model_eval,train,evaluation,main,load_lawschool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_function import plot_compas_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need:  \n",
    "MLclassifier.py  \n",
    "plot_function.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn shape (3694, 10)\n",
      "(3694, 22) (3694,) (1584, 22) (1584,)\n",
      "Ada training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAT\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisiontree training...\n",
      "randomforeast training...\n",
      "MLPClassifier...\n",
      "logistic regression training ... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.7239</td>\n",
       "      <td>0.6957</td>\n",
       "      <td>0.7007</td>\n",
       "      <td>0.7295</td>\n",
       "      <td>0.7148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.7160</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.7179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.7058</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.7313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.7323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.7446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train_acc  test_acc  precision  recall  f1_score\n",
       "DecisionTree           0.7239    0.6957     0.7007  0.7295    0.7148\n",
       "RandomForest           0.7160    0.7083     0.7259  0.7101    0.7179\n",
       "MLPC                   0.7063    0.7058     0.6998  0.7657    0.7313\n",
       "AdaBoost               0.7174    0.7165     0.7232  0.7415    0.7323\n",
       "LogisticRegression     0.6800    0.7146     0.6996  0.7959    0.7446"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compas\n",
    "from sklearn.preprocessing import Normalizer,OneHotEncoder,RobustScaler\n",
    "def load_syn_data():\n",
    "    \n",
    "    syn  = pd.read_csv(\"./GenerateData/Compas/Compas_train.csv\") \n",
    "    print(\"syn shape\",syn.shape)\n",
    "    test = pd.read_csv(\"./GenerateData/Compas_test.csv\")\n",
    "    data = pd.concat([syn,test],axis=0)\n",
    "    \n",
    "    y = data['two_year_recid']\n",
    "    features = data.drop(['two_year_recid'], axis=1)\n",
    "    c_vars = ['age','diff_custody','diff_jail','priors_count']\n",
    "    cat_vars = [col for col in features.columns if col not in c_vars]\n",
    "    \n",
    "    scaler = Normalizer()\n",
    "    features_c = scaler.fit_transform(features[c_vars])\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    onehot = enc.fit_transform(features[cat_vars]).toarray()\n",
    "    X =  np.concatenate((features_c,onehot ),axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y ,test_size=0.3, shuffle=False)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test \n",
    "    \n",
    "X_train, X_test, y_train, y_test  = load_syn_data()\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "overall_eval = main(X_train,y_train,X_test,y_test)    \n",
    "overall_eval    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adult\n",
    "from sklearn.preprocessing import Normalizer,OneHotEncoder\n",
    "def load_syn_data():\n",
    "    \n",
    "    syn  = pd.read_csv(\"./GenerateData/Adult/Adult_06_03.csv\") \n",
    "    print(\"syn shape\",syn.shape)\n",
    "    test = pd.read_csv(\"./GenerateData/Adult/Adult_test.csv\")\n",
    "    data = pd.concat([syn,test],axis=0)\n",
    "    \n",
    "    y = data['Income']\n",
    "    features = data.drop(['Income'], axis=1)\n",
    "    c_vars = ['Age','HoursPerWeek','EducationNum']\n",
    "    cat_vars = [col for col in features.columns if col not in c_vars]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    features_c = scaler.fit_transform(features[c_vars])\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    onehot = enc.fit_transform(features[cat_vars]).toarray()\n",
    "    X =  np.concatenate((features_c,onehot ),axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y ,test_size=0.3, shuffle=False)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "X_train, X_test, y_train, y_test  = load_syn_data()\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "overall_eval = main(X_train,y_train,X_test,y_test)    \n",
    "overall_eval    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn shape (60215, 8)\n",
      "(25807, 8)\n",
      "(60215, 38) (60215,) (25807, 38) (25807,)\n",
      "Ada training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAT\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisiontree training...\n",
      "randomforeast training...\n",
      "MLPClassifier...\n",
      "logistic regression training ... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.7919</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.4876</td>\n",
       "      <td>0.5704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.8021</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.4580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.8443</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.8384</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.7436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8399</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>0.7516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train_acc  test_acc  precision  recall  f1_score\n",
       "DecisionTree           0.7919    0.8024     0.6870  0.4876    0.5704\n",
       "RandomForest           0.7845    0.7959     0.8021  0.3205    0.4580\n",
       "MLPC                   0.8443    0.8615     0.7351  0.7587    0.7467\n",
       "AdaBoost               0.8384    0.8650     0.7600  0.7279    0.7436\n",
       "LogisticRegression     0.8399    0.8702     0.7741  0.7305    0.7516"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lawschool\n",
    "from sklearn.preprocessing import Normalizer,OneHotEncoder\n",
    "def load_syn_data():\n",
    "    \n",
    "    syn = pd.read_csv(\"./GenerateData/lawschool/lawschool_syn_new.csv\")\n",
    "    syn = syn[0:60215]\n",
    "    print(\"syn shape\",syn.shape)\n",
    "    test = pd.read_csv(\"./GenerateData/lawschool/lawschool_test.csv\")\n",
    "    print(test.shape)\n",
    "    data = pd.concat([syn,test],axis=0)\n",
    "    \n",
    "    y = data['admit']\n",
    "    features = data.drop(['admit'], axis=1)\n",
    "    c_vars = ['lsat','gpa']\n",
    "    cat_vars = [col for col in features.columns if col not in c_vars]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    features_c = scaler.fit_transform(features[c_vars])\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    onehot = enc.fit_transform(features[cat_vars]).toarray()\n",
    "    X =  np.concatenate((features_c,onehot ),axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y ,test_size=test.shape[0]/(syn.shape[0]+test.shape[0]), shuffle=False)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "X_train, X_test, y_train, y_test  = load_syn_data()\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "overall_eval = main(X_train,y_train,X_test,y_test)    \n",
    "overall_eval    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn shape (79100, 87)\n",
      "(33900, 87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAT\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79100, 97) (79100,) (33900, 97) (33900,)\n",
      "Ada training...\n",
      "decisiontree training...\n",
      "randomforeast training...\n",
      "MLPClassifier...\n",
      "logistic regression training ... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>0.8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.8026</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.8344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.8470</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.8475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>0.8195</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.8511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8035</td>\n",
       "      <td>0.7971</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>0.8421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train_acc  test_acc  precision  recall  f1_score\n",
       "DecisionTree           0.7979    0.7964     0.8286  0.8236    0.8261\n",
       "RandomForest           0.8026    0.7973     0.8019  0.8696    0.8344\n",
       "MLPC                   0.8470    0.8162     0.8262  0.8698    0.8475\n",
       "AdaBoost               0.8230    0.8181     0.8195  0.8852    0.8511\n",
       "LogisticRegression     0.8085    0.8035     0.7971  0.8925    0.8421"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#health\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
    "def load_syn_data():\n",
    "    \n",
    "    #data = pd.read_csv(\"./GenerateData/health/health_after_preprocess.csv\")\n",
    "    syn = pd.read_csv(\"./GenerateData/health/ctgan/health_syn_ctgan.csv\")\n",
    "    print(\"syn shape\",syn.shape)\n",
    "    test = pd.read_csv(\"./GenerateData/health/ctgan/health_test_ctgan.csv\")\n",
    "    print(test.shape)\n",
    "    data = pd.concat([syn,test],axis=0)\n",
    "    \n",
    "    y = data['max_CharlsonIndex']\n",
    "    features = data.drop(['max_CharlsonIndex'], axis=1)\n",
    "    \n",
    "    continous= ['LabCount_total','LabCount_months', 'DrugCount_total','DrugCount_months', 'PayDelay_total', 'PayDelay_max', 'PayDelay_min']\n",
    "    other = [col for col in features.columns if '=' in col]\n",
    "    continous.extend(other)\n",
    "    cat_vars = [col for col in features.columns if col not in continous]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    features_c = scaler.fit_transform(features[continous])\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    onehot = enc.fit_transform(features[cat_vars]).toarray()\n",
    "    X =  np.concatenate((features_c,onehot ),axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y ,test_size=0.3, random_state=2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "X_train, X_test, y_train, y_test  = load_syn_data()\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "overall_eval = main(X_train,y_train,X_test,y_test)    \n",
    "overall_eval    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def plot_adult_distribution(real,fake):\n",
    "    sns.set(style=\"ticks\", color_codes=True,font_scale=1.5)\n",
    "    con_vars = ['lsat', 'gpa']\n",
    "    cat_vars = [columns for columns in fake.columns if columns not in con_vars]\n",
    "\n",
    "    real['label']=1\n",
    "    fake['label']= 0\n",
    "    df = pd.concat([real,fake],axis=0)\n",
    "\n",
    "    for column in  fake.columns:\n",
    "        if column in con_vars:\n",
    "            sns.distplot(fake[column],bins=100,kde = False,label='fake')\n",
    "            sns.distplot(real[column],bins=100,kde = False,label='real')\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.savefig('./figure/lawschool/CTGAN/'+column + '.png', dpi=600,bbox_inches = 'tight')\n",
    "            plt.show()\n",
    "        else:\n",
    "            sns.countplot(x=column,data = df, hue=\"label\")\n",
    "            plt.savefig('./figure/lawschool/CTGAN/'+column + '.png', dpi=600,bbox_inches = 'tight')\n",
    "            plt.show()\n",
    "plot_adult_distribution(real,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def plot_adult_distribution(real,fake):\n",
    "    sns.set(style=\"ticks\", color_codes=True,font_scale=1.5)\n",
    "    con_vars = ['age','fnlwgt','capital-gain','capital-loss','hours-per-week']\n",
    "    cat_vars = [columns for columns in fake.columns if columns not in con_vars]\n",
    "\n",
    "    real['label']=1\n",
    "    fake['label']= 0\n",
    "    df = pd.concat([real,fake],axis=0)\n",
    "\n",
    "    for column in  fake.columns:\n",
    "        if column in con_vars:\n",
    "            sns.distplot(fake[column],bins=100,kde = False,label='fake')\n",
    "            sns.distplot(real[column],bins=100,kde = False,label='real')\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.savefig('./figure/Adult/CTGAN/'+column + '.png', dpi=600,bbox_inches = 'tight')\n",
    "            plt.show()\n",
    "        else:\n",
    "            sns.countplot(x=column,data = df, hue=\"label\")\n",
    "            plt.savefig('./figure/Adult/CTGAN/'+column + '.png', dpi=600,bbox_inches = 'tight')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name =['adult_fake_epoch250','adult_fake_epoch250_v2','adult_fake_epoch250_v3','adult_fake_epoch250_v4','adult_fake_epoch250_v5']\n",
    "file_name =['adult_fake_epoch150','adult_fake_epoch150_v2','adult_fake_epoch150_v3','adult_fake_epoch150_v4','adult_fake_epoch150_v5']\n",
    "file_name =['adult_fake_epoch100','adult_fake_epoch100_v2','adult_fake_epoch100_v3','adult_fake_epoch100_v4','adult_fake_epoch100_v5']\n",
    "file_name =['adult_fake_10','adult_fake_10_v2','adult_fake_epoch300_v3','adult_fake_epoch300_v4','adult_fake_epoch300_v5']\n",
    "['adult_fake_epoch350','adult_fake_epoch350_v2','adult_fake_epoch350_v3','adult_fake_epoch350_v4','adult_fake_epoch350_v5']\n",
    "['adult_fake_epoch400','adult_fake_epoch400_v2','adult_fake_epoch400_v3','adult_fake_epoch400_v4','adult_fake_epoch400_v5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name =['adult_fake_epoch30','adult_fake_epoch30_v2','adult_fake_epoch30_v3','adult_fake_epoch30_v4','adult_fake_epoch30_v5']\n",
    "\n",
    "l=[]\n",
    "mean= []\n",
    "for i in range(5):\n",
    "    print(\"interation:\",i)\n",
    "    for file in file_name:\n",
    "        print(file)\n",
    "        X_train, X_test, y_train, y_test = load_syn_adult_data(file)\n",
    "        overall_eval_new = main(X_train,y_train,X_test,y_test)\n",
    "        l.append(overall_eval_new)\n",
    "\n",
    "    mean_iter = (l[0]+l[1]+l[2]+l[3]+l[4])/5\n",
    "    mean.append(mean_iter)\n",
    "(mean[0]+mean[1]+mean[2]+mean[3]+mean[4])/5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
